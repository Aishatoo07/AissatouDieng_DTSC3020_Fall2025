{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aishatoo07/AissatouDieng_DTSC3020_Fall2025/blob/main/Assignment_6_WebScraping_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_de5Eq4u-tR"
      },
      "source": [
        "# Assignment 6 (4 points) — Web Scraping\n",
        "\n",
        "In this assignment you will complete **two questions**. The **deadline is posted on Canvas**.\n"
      ],
      "id": "H_de5Eq4u-tR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PHwamZMu-tX"
      },
      "source": [
        "## Assignment Guide (Read Me First)\n",
        "\n",
        "- This notebook provides an **Install Required Libraries** cell and a **Common Imports & Polite Headers** cell. Run them first.\n",
        "- Each question includes a **skeleton**. The skeleton is **not** a solution; it is a lightweight scaffold you may reuse.\n",
        "- Under each skeleton you will find a **“Write your answer here”** code cell. Implement your scraping, cleaning, and saving logic there.\n",
        "- When your code is complete, run the **Runner** cell to print a Top‑15 preview and save the CSV.\n",
        "- Expected outputs:\n",
        "  - **Q1:** `data_q1.csv` + Top‑15 sorted by the specified numeric column.\n",
        "  - **Q2:** `data_q2.csv` + Top‑15 sorted by `points`.\n"
      ],
      "id": "4PHwamZMu-tX"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I7DLq9nEu-tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8454872-7b01-4946-8038-e70d99c56a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "#Install Required Libraries\n",
        "!pip -q install requests beautifulsoup4 lxml pandas\n",
        "print(\"Dependencies installed.\")\n"
      ],
      "id": "I7DLq9nEu-tZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug_A9RuPu-tb"
      },
      "source": [
        "### 2) Common Imports & Polite Headers"
      ],
      "id": "ug_A9RuPu-tb"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ov8pXh65u-tc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d11682-97c8-484a-843b-f518cfb86b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common helpers loaded.\n"
          ]
        }
      ],
      "source": [
        "# Common Imports & Polite Headers\n",
        "import re, sys, pandas as pd, requests\n",
        "from bs4 import BeautifulSoup\n",
        "HEADERS = {\"User-Agent\": (\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "    \"(KHTML, like Gecko) Chrome/122.0 Safari/537.36\")}\n",
        "def fetch_html(url: str, timeout: int = 20) -> str:\n",
        "    r = requests.get(url, headers=HEADERS, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "def flatten_headers(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = [\" \".join([str(x) for x in tup if str(x)!=\"nan\"]).strip()\n",
        "                      for tup in df.columns.values]\n",
        "    else:\n",
        "        df.columns = [str(c).strip() for c in df.columns]\n",
        "    return df\n",
        "print(\"Common helpers loaded.\")\n"
      ],
      "id": "Ov8pXh65u-tc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km0GO7zzu-td"
      },
      "source": [
        "## Question 1 — IBAN Country Codes (table)\n",
        "**URL:** https://www.iban.com/country-codes  \n",
        "**Extract at least:** `Country`, `Alpha-2`, `Alpha-3`, `Numeric` (≥4 cols; you may add more)  \n",
        "**Clean:** trim spaces; `Alpha-2/Alpha-3` → **UPPERCASE**; `Numeric` → **int** (nullable OK)  \n",
        "**Output:** write **`data_q1.csv`** and **print a Top-15** sorted by `Numeric` (desc, no charts)  \n",
        "**Deliverables:** notebook + `data_q1.csv` + short `README.md` (URL, steps, 1 limitation)\n",
        "\n",
        "**Tip:** You can use `pandas.read_html(html)` to read tables and then pick one with ≥3 columns.\n"
      ],
      "id": "km0GO7zzu-td"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q1_skeleton"
      },
      "outputs": [],
      "source": [
        "# --- Q1 Skeleton (fill the TODOs) ---\n",
        "def q1_read_table(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Return the first table with >= 3 columns from the HTML.\n",
        "    TODO: implement with pd.read_html(html), pick a reasonable table, then flatten headers.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_read_table\")\n",
        "\n",
        "def q1_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean columns: strip, UPPER Alpha-2/Alpha-3, cast Numeric to int (nullable), drop invalids.\n",
        "    TODO: implement cleaning steps.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_clean\")\n",
        "\n",
        "def q1_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort descending by Numeric and return Top-N.\n",
        "    TODO: implement.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"TODO: implement q1_sort_top\")\n"
      ],
      "id": "q1_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q1_skeleton_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ca824a-7c71-42e4-b638-7675534365c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 — Top-15 by Numeric (desc):\n",
            "                                                   Country Alpha-2 Alpha-3  Numeric\n",
            "                                                    Zambia      ZM     ZMB      894\n",
            "                                                     Yemen      YE     YEM      887\n",
            "                                                     Samoa      WS     WSM      882\n",
            "                                         Wallis and Futuna      WF     WLF      876\n",
            "                        Venezuela (Bolivarian Republic of)      VE     VEN      862\n",
            "                                                Uzbekistan      UZ     UZB      860\n",
            "                                                   Uruguay      UY     URY      858\n",
            "                                              Burkina Faso      BF     BFA      854\n",
            "                                     Virgin Islands (U.S.)      VI     VIR      850\n",
            "                            United States of America (the)      US     USA      840\n",
            "                              Tanzania, United Republic of      TZ     TZA      834\n",
            "                                               Isle of Man      IM     IMN      833\n",
            "                                                    Jersey      JE     JEY      832\n",
            "                                                  Guernsey      GG     GGY      831\n",
            "United Kingdom of Great Britain and Northern Ireland (the)      GB     GBR      826\n",
            "\n",
            "Saved: data_q1.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3967212036.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  tables = pd.read_html(html)  # requires lxml\n"
          ]
        }
      ],
      "source": [
        "# Q1 — IBAN Country Codes (table)\n",
        "# URL: https://www.iban.com/country-codes\n",
        "# Expected: data_q1.csv + Top-15 sorted by Numeric (desc)\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "URL = \"https://www.iban.com/country-codes\"\n",
        "UA = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0 Safari/537.36\"}\n",
        "\n",
        "# --- Implementations for the 3 TODOs ---\n",
        "\n",
        "def q1_read_table(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Return the first table with >= 3 columns from the HTML.\"\"\"\n",
        "    tables = pd.read_html(html)  # requires lxml\n",
        "    if not tables:\n",
        "        raise ValueError(\"No tables found in HTML.\")\n",
        "\n",
        "    # Flatten headers for each candidate table\n",
        "    def _flatten(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        if isinstance(df.columns, pd.MultiIndex):\n",
        "            df.columns = [\" \".join([str(x) for x in tup if str(x) != \"nan\"]).strip()\n",
        "                          for tup in df.columns.values]\n",
        "        else:\n",
        "            df.columns = [str(c).strip() for c in df.columns]\n",
        "        return df\n",
        "\n",
        "    chosen = None\n",
        "    for t in tables:\n",
        "        t = _flatten(t)\n",
        "        if t.shape[1] >= 3:\n",
        "            chosen = t\n",
        "            break\n",
        "    if chosen is None:\n",
        "        raise ValueError(\"No suitable table (>= 3 columns) found.\")\n",
        "\n",
        "    # Canonicalize header names (keep extras)\n",
        "    canon = {\n",
        "        \"country\": \"Country\",\n",
        "        \"country name\": \"Country\",\n",
        "        \"alpha-2 code\": \"Alpha-2\",\n",
        "        \"alpha 2 code\": \"Alpha-2\",\n",
        "        \"alpha2\": \"Alpha-2\",\n",
        "        \"alpha-3 code\": \"Alpha-3\",\n",
        "        \"alpha 3 code\": \"Alpha-3\",\n",
        "        \"alpha3\": \"Alpha-3\",\n",
        "        \"numeric\": \"Numeric\",\n",
        "        \"numeric code\": \"Numeric\",\n",
        "    }\n",
        "    new_cols = []\n",
        "    for c in chosen.columns:\n",
        "        key = str(c).strip().lower()\n",
        "        new_cols.append(canon.get(key, str(c).strip()))\n",
        "    chosen.columns = new_cols\n",
        "    return chosen\n",
        "\n",
        "\n",
        "def q1_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean columns: strip, UPPER Alpha-2/Alpha-3, cast Numeric to int (nullable), drop invalids.\"\"\"\n",
        "    out = df.copy()\n",
        "\n",
        "    # Ensure required columns exist (keep extras)\n",
        "    req = [\"Country\", \"Alpha-2\", \"Alpha-3\", \"Numeric\"]\n",
        "    for c in req:\n",
        "        if c not in out.columns:\n",
        "            out[c] = pd.NA\n",
        "\n",
        "    # Strip whitespace on object columns\n",
        "    for c in out.select_dtypes(include=[\"object\"]).columns:\n",
        "        out[c] = out[c].astype(str).str.strip()\n",
        "\n",
        "    # Uppercase codes\n",
        "    out[\"Alpha-2\"] = out[\"Alpha-2\"].astype(str).str.strip().str.upper().replace({\"<NA>\": pd.NA})\n",
        "    out[\"Alpha-3\"] = out[\"Alpha-3\"].astype(str).str.strip().str.upper().replace({\"<NA>\": pd.NA})\n",
        "\n",
        "    # Numeric -> nullable Int64\n",
        "    out[\"Numeric\"] = pd.to_numeric(out[\"Numeric\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    # Drop invalid/blank Country\n",
        "    out[\"Country\"] = out[\"Country\"].replace({\"nan\": pd.NA}).astype(\"string\").str.strip()\n",
        "    out = out.dropna(subset=[\"Country\"]).reset_index(drop=True)\n",
        "\n",
        "    # Put required 4 first\n",
        "    ordered = [c for c in req if c in out.columns] + [c for c in out.columns if c not in req]\n",
        "    return out[ordered]\n",
        "\n",
        "\n",
        "def q1_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort descending by Numeric and return Top-N.\"\"\"\n",
        "    return (\n",
        "        df.sort_values(by=\"Numeric\", ascending=False, na_position=\"last\")\n",
        "          .head(top)\n",
        "          .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "# --- Fetch -> Parse -> Clean -> Save -> Print Top-15 ---\n",
        "html = requests.get(URL, headers=UA, timeout=20).text\n",
        "raw = q1_read_table(html)\n",
        "clean = q1_clean(raw)\n",
        "clean.to_csv(\"data_q1.csv\", index=False)\n",
        "\n",
        "top15 = q1_sort_top(clean, top=15)\n",
        "print(\"Q1 — Top-15 by Numeric (desc):\")\n",
        "print(top15.to_string(index=False))\n",
        "print(\"\\nSaved: data_q1.csv\")\n",
        "\n",
        "# (Optional) Minimal README.md for your deliverables\n",
        "readme = \"\"\"# Assignment 6 — Q1: IBAN Country Codes\n",
        "- URL: https://www.iban.com/country-codes\n",
        "- Steps:\n",
        "  1) Fetch page HTML with a polite User-Agent.\n",
        "  2) Use `pandas.read_html` to extract the first table with ≥3 columns.\n",
        "  3) Clean columns: trim whitespace; uppercase Alpha-2/Alpha-3; cast Numeric to nullable Int64.\n",
        "  4) Save as `data_q1.csv`.\n",
        "  5) Print Top-15 rows sorted by `Numeric` (descending).\n",
        "- Limitation:\n",
        "  - Relies on the site’s current table structure and header texts; if they change, header mapping may need updating.\n",
        "\"\"\"\n",
        "with open(\"README.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(readme)\n"
      ],
      "id": "q1_skeleton_answer"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmefu--_u-tg"
      },
      "source": [
        "## Question 2 — Hacker News (front page)\n",
        "**URL:** https://news.ycombinator.com/  \n",
        "**Extract at least:** `rank`, `title`, `link`, `points`, `comments` (user optional)  \n",
        "**Clean:** cast `points`/`comments`/`rank` → **int** (non-digits → 0), fill missing text fields  \n",
        "**Output:** write **`data_q2.csv`** and **print a Top-15** sorted by `points` (desc, no charts)  \n",
        "**Tip:** Each story is a `.athing` row; details (points/comments/user) are in the next `<tr>` with `.subtext`.\n"
      ],
      "id": "rmefu--_u-tg"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q2_skeleton"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "_DIGITS = re.compile(r\"(\\d+)\")\n",
        "\n",
        "def _to_int(x) -> int:\n",
        "    \"\"\"Extract first digits from text; non-digits -> 0.\"\"\"\n",
        "    if x is None:\n",
        "        return 0\n",
        "    m = _DIGITS.search(str(x))\n",
        "    return int(m.group(1)) if m else 0\n",
        "\n",
        "def q2_parse_items(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Parse front page items into: rank, title, link, points, comments, user.\"\"\"\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    rows = []\n",
        "    for athing in soup.select(\"tr.athing\"):\n",
        "        # rank/title/link from the athing row\n",
        "        rank_txt = (athing.select_one(\".rank\").get_text(strip=True) if athing.select_one(\".rank\") else \"\")\n",
        "        title_a = athing.select_one(\".titleline a\")\n",
        "        title = title_a.get_text(strip=True) if title_a else \"\"\n",
        "        link = title_a.get(\"href\", \"\") if title_a else \"\"\n",
        "\n",
        "        # details from the immediate sibling row's .subtext\n",
        "        points, comments, user = 0, 0, \"\"\n",
        "        subrow = athing.find_next_sibling(\"tr\")\n",
        "        if subrow:\n",
        "            sub = subrow.select_one(\".subtext\")\n",
        "            if sub:\n",
        "                score = sub.select_one(\".score\")\n",
        "                points = _to_int(score.get_text(strip=True) if score else \"\")\n",
        "\n",
        "                u = sub.select_one(\".hnuser\")\n",
        "                user = u.get_text(strip=True) if u else \"\"\n",
        "\n",
        "                a_tags = sub.select(\"a\")\n",
        "                if a_tags:\n",
        "                    comments_txt = a_tags[-1].get_text(strip=True)  # usually \"... comments\" or \"discuss\"\n",
        "                    comments = _to_int(comments_txt)\n",
        "\n",
        "        rows.append({\n",
        "            \"rank\": _to_int(rank_txt),\n",
        "            \"title\": title,\n",
        "            \"link\": link,\n",
        "            \"points\": points,\n",
        "            \"comments\": comments,\n",
        "            \"user\": user\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def q2_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Cast points/comments/rank to int (non-digits->0); fill text fields.\"\"\"\n",
        "    out = df.copy()\n",
        "\n",
        "    # Ensure text fields exist and are clean\n",
        "    for col in [\"title\", \"link\", \"user\"]:\n",
        "        if col not in out.columns:\n",
        "            out[col] = \"\"\n",
        "        out[col] = out[col].fillna(\"\").astype(str).str.strip()\n",
        "\n",
        "    # Ensure numeric fields exist and coerce to int via digit extraction\n",
        "    for col in [\"rank\", \"points\", \"comments\"]:\n",
        "        if col not in out.columns:\n",
        "            out[col] = 0\n",
        "        out[col] = out[col].apply(_to_int).astype(int)\n",
        "\n",
        "    return out\n",
        "\n",
        "def q2_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort by points desc and return Top-N.\"\"\"\n",
        "    return df.sort_values(\"points\", ascending=False, na_position=\"last\").head(top).reset_index(drop=True)\n"
      ],
      "id": "q2_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "q2_skeleton_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5b10fb-d95e-4ba1-e81c-4e51735278ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q2 — Top-15 by points (desc):\n",
            " rank                                                                       title                                                                                                                                                                link  points  comments         user\n",
            "   13 YouTube Removes Windows 11 Bypass Tutorials, Claims 'Risk of Physical Harm'                                                                                               https://news.itsfoss.com/youtube-removes-windows-11-bypass-tutorials/     418       158  WaitWaitWha\n",
            "   10                                                     Why I love OCaml (2023)                                                                                                                     https://mccd.space/posts/ocaml-the-worlds-best/     300       204        art-w\n",
            "   22              VLC's Jean-Baptiste Kempf Receives the European SFS Award 2025                                                                                                                 https://fsfe.org/news/2025/news-20251107-01.en.html     251        41    kirschner\n",
            "   25                                                       James Watson has died                                                                                                   https://www.nytimes.com/2025/11/07/science/james-watson-dead.html     242       137    granzymes\n",
            "    5    Myna: Monospace typeface designed for symbol-heavy programming languages                                                                                                                              https://github.com/sayyadirfanali/Myna     207        81  birdculture\n",
            "    8                                                      Ruby Solved My Problem                                                                                                   https://newsletter.masilotti.com/p/ruby-already-solved-my-problem     176        69 joemasilotti\n",
            "    1                                                         Why is Zig so cool?                                                                                                             https://nilostolte.github.io/tech/articles/ZigCool.html     169        59    vitalnodo\n",
            "    7                                                         How did I get here?                                                                                                                                     https://how-did-i-get-here.net/     130        33    zachlatta\n",
            "    3                                                Becoming a Compiler Engineer                                                                                                            https://rona.substack.com/p/becoming-a-compiler-engineer     125        50    lalitkale\n",
            "   23                                              Angel Investors, a Field Guide                                                                                                       https://www.jeanyang.com/posts/angel-investors-a-field-guide/     108        22     azhenley\n",
            "   20               FAA to restrict commercial rocket launches to overnight hours https://www.space.com/space-exploration/launches-spacecraft/faa-restricts-commercial-rocket-launches-indefinitely-due-to-air-traffic-risks-from-government-shutdown      98        37      bookmtn\n",
            "   17                                                     Venn Diagram for 7 Sets                                                                                                                              https://moebio.com/research/sevensets/      97        21  bramadityaw\n",
            "    2                   Snapchat open-sources Valdi a cross-platform UI framework                                                                                                                                   https://github.com/Snapchat/Valdi      87        21  yehiaabdelm\n",
            "   12                                              Sam Altman's pants are on fire                                                                                                  https://garymarcus.substack.com/p/sam-altmans-pants-are-totally-on      83        28  toomuchtodo\n",
            "   16                    Transducer: Composition, abstraction, performance (2018)                                                                                                 https://funktionale-programmierung.de/en/2018/03/22/transducer.html      76         0     defmarco\n",
            "\n",
            "Saved: data_q2.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "URL = \"https://news.ycombinator.com/\"\n",
        "UA = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0 Safari/537.36\"}\n",
        "\n",
        "html = requests.get(URL, headers=UA, timeout=20).text\n",
        "raw = q2_parse_items(html)\n",
        "clean = q2_clean(raw)\n",
        "clean.to_csv(\"data_q2.csv\", index=False)\n",
        "\n",
        "top15 = q2_sort_top(clean, top=15)\n",
        "print(\"Q2 — Top-15 by points (desc):\")\n",
        "print(top15.to_string(index=False))\n",
        "print(\"\\nSaved: data_q2.csv\")\n"
      ],
      "id": "q2_skeleton_answer"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}